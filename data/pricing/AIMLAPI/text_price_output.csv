name,2024-06-18,2024-07-03,2024-08-26,2024-09-27,2024-10-21
01-ai yi base (6b),0.25999999999999995,,,0.21000000000000002,0.21000000000000002
alpaca (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
chat gpt 3.5 turbo,,,,4.2,4.2
chat gpt 4,,,,63.0,63.0
chat gpt 4 32k,,,,126.0,126.0
chat gpt 4 turbo,,,,31.5,31.5
chat gpt 4o mini,,,,0.63,0.63
chat gpt-3.5 turbo 0125,,,,1.58,1.58
chat gpt-3.5 turbo 1106,,,,2.1,2.1
chat gpt-3.5 turbo instruct,,,,2.1,2.1
chat gpt-4o,,,,15.75,15.75
claude 3 haiku,,,,1.31,1.31
claude 3 opus,,,,78.75,78.75
claude 3 sonnet,,,,15.75,15.75
claude 3.5 sonnet,,,,15.75,15.75
claude 3.5 sonnet 20241022,,,,15.75,15.75
claude-3-haiku,1.625,1.625,1.625,,
claude-3-opus,97.5,97.5,97.5,,
claude-3-sonnet,19.5,19.5,19.5,,
claude-3.5-sonnet,,,19.5,,
code llama (70b),,1.17,1.17,0.94,0.94
code llama instruct (13b),0.39,0.39,0.39,0.23,0.23
code llama instruct (34b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.82,0.82
code llama instruct (70b),,1.17,1.17,0.94,0.94
code llama instruct (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
code llama python (13b),0.39,0.39,0.39,0.23,0.23
code llama python (34b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.82,0.82
code llama python (70b),,1.17,1.17,0.94,0.94
code llama python (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
codegen2 (16b),,0.39,0.39,0.21000000000000002,0.21000000000000002
codegen2 (7b),,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
dbrx instruct,,,,1.26,1.26
deepseek coder instruct (33b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.8400000000000001,0.8400000000000001
deepseek-llm-67b-chat,1.0399999999999998,1.0399999999999998,1.0399999999999998,0.94,0.94
discolm mixtral 8x7b (46.7b),,,,0.63,0.63
dolly v2 (12b),,,,0.32,0.32
dolly v2 (3b),,,,0.11,0.11
dolly v2 (7b),,,,0.21000000000000002,0.21000000000000002
dolly-v2-12b,0.39,0.39,0.39,,
dolphin-2.5-mixtral-8x7b,1.17,1.17,1.17,0.63,0.63
evo-1 8k base,,0.12999999999999998,0.12999999999999998,,
falcon (40b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.8400000000000001,0.8400000000000001
falcon (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
falcon instruct (40b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.8400000000000001,0.8400000000000001
falcon instruct (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
flan t5,0.12999999999999998,0.12999999999999998,0.12999999999999998,,
flan t5 xl (3b),,0.12999999999999998,0.12999999999999998,0.11,0.11
gemini 1.0 pro,,,,0.39,0.39
gemini 1.5 flash,,,,0.16,0.16
gemini 1.5 pro,,,,7.88,7.88
gemma (2b),,0.12999999999999998,0.12999999999999998,0.11,0.11
gemma (7b),,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
gemma 2 (9b),,,,0.32,0.32
gpt neox 20b,,0.39,0.39,0.32,0.32
gpt-3.5-turbo,1.95,1.95,1.95,,
gpt-3.5-turbo-0613,2.6,2.6,2.6,,
gpt-3.5-turbo-16k,5.2,5.2,5.2,,
gpt-3.5-turbo-16k-0613,5.2,5.2,5.2,,
gpt-3.5-turbo-instruct,2.6,2.6,2.6,,
gpt-4,78.0,78.0,78.0,,
gpt-4-0613,78.0,78.0,78.0,,
gpt-4-32k,156.0,156.0,156.0,,
gpt-4-32k-0613,156.0,156.0,156.0,,
gpt-4-turbo,39.0,39.0,39.0,,
gpt-4o,19.5,19.5,19.5,,
gpt-4o mini,,,0.9,,
gpt-4o-2024-05-13,,,,5.25,5.25
gpt-4o-2024-08-06,,,,10.5,10.5
gpt-jt-moderation (6b),,,,0.21000000000000002,0.21000000000000002
gpt-neox-20b,0.39,0.39,0.39,,
gpt-neoxt-chat-base-20b,0.39,0.39,0.39,0.32,0.32
guanaco (13b),,,,0.32,0.32
guanaco (33b),,,,0.8400000000000001,0.8400000000000001
guanaco (65b),,,,0.94,0.94
guanaco (7b),,,,0.21000000000000002,0.21000000000000002
hermes 2 theta llama-3 70b,,,,0.5199999999999999,0.5199999999999999
koala (13b),,,,0.32,0.32
koala (7b),,,,0.21000000000000002,0.21000000000000002
llama 3 70b instruct lite,,,,0.57,0.57
llama 3 70b instruct reference,,,,0.94,0.94
llama 3 8b instruct lite,,,,0.11,0.11
llama 3 8b instruct reference,,,,0.21000000000000002,0.21000000000000002
llama 3.1 (405b) instruct turbo,,,,5.25,5.25
llama 3.1 70b instruct turbo,,,,0.92,0.92
llama 3.1 8b instruct turbo,,,,0.19,0.19
llama 3.2 11b vision instruct turbo,,,,0.19,0.19
llama 3.2 3b instruct turbo,,,,0.060000000000000005,0.060000000000000005
llama 3.2 90b vision instruct turbo,,,,1.26,1.26
llama-2 (13b),0.39,0.39,0.39,0.23,0.23
llama-2 (70b),1.17,1.17,1.17,,
llama-2 (7b),,,,0.21000000000000002,0.21000000000000002
llama-2 chat (13b),0.39,0.39,0.39,0.23,0.23
llama-2 chat (70b),1.17,1.17,1.17,0.94,0.94
llama-2 chat (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
llama-2-32k (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
llama-2-7b-32k-instruct (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
llama-3 (70b),,1.17,1.17,0.94,0.94
llama-3 (8b),,0.25999999999999995,0.25999999999999995,,
llama-3 70b gradient instruct,,,,0.5199999999999999,0.5199999999999999
llama-3 chat (70b),,,,0.94,0.94
llama-3 chat (8b),,,,0.21000000000000002,0.21000000000000002
llama-3-70b instruct lite,,,0.7020000000000001,,
llama-3.1-70b instruct turbo,,,6.5,,
llama-3.1-8b instruct turbo,,,0.12999999999999998,,
llava v1.6 - mistral 7b,,,,0.19,0.19
meta llama 3 70b instruct,1.17,1.17,1.17,,
meta llama 3 8b instruct,0.25999999999999995,0.25999999999999995,0.25999999999999995,,
microsoft phi-2,,0.12999999999999998,0.12999999999999998,0.11,0.11
mistral (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,,
mistral (7b) instruct,0.25999999999999995,0.25999999999999995,0.25999999999999995,,
mistral (7b) instruct v0.3,,,,0.21000000000000002,0.21000000000000002
mistral 7b instruct v0.3,0.25999999999999995,,0.25999999999999995,,
mixtral 7b,,,,0.21000000000000002,0.21000000000000002
mixtral 8x22b,1.17,1.56,1.56,1.26,1.26
mixtral 8x22b instruct,1.17,1.17,1.17,1.26,1.26
mixtral-8x7b v0.1,,,,0.63,0.63
mpt-chat (30b),,,,0.8400000000000001,0.8400000000000001
mpt-chat (7b),,,,0.21000000000000002,0.21000000000000002
mythomax-l2 (13b),0.39,0.39,0.39,0.32,0.32
nexusraven (13b),0.39,0.39,0.39,0.32,0.32
nous capybara v1.9 (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
nous hermes 2 - mixtral 8x7b-dpo,1.17,1.17,1.17,,
nous hermes llama-2 (13b),0.39,0.39,0.39,0.32,0.32
nous hermes llama-2 (70b),,,,0.94,0.94
nous hermes llama-2 (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
nous hermes-2 yi (34b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.8400000000000001,0.8400000000000001
olmo twin-2t (7b),,,,0.21000000000000002,0.21000000000000002
olmo-7b,0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
olmo-7b-instruct,0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
open-assistant pythia sft-4 (12b),,,,0.32,0.32
open-assistant stablelm sft-7 (7b),,,,0.21000000000000002,0.21000000000000002
openai o1-mini,,,,12.6,12.6
openai o1-preview,,,,15.7,15.7
openchat 3.5,0.39,0.39,0.39,,
openchat 3.5 (7b),,,,0.21000000000000002,0.21000000000000002
openhermes-2-mistral (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
openhermes-2.5-mistral (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
openorca mistral (7b),,,,0.21000000000000002,0.21000000000000002
openorca mistral (7b) 8k,0.25999999999999995,0.25999999999999995,0.25999999999999995,,
phind code llama v2 (34b),1.0399999999999998,1.0399999999999998,1.0399999999999998,0.8400000000000001,0.8400000000000001
platypus2 instruct (70b),1.17,1.17,1.17,,
platypus2-70b-instruct,1.17,1.17,1.17,0.94,0.94
pythia-chat-base (7b),,,,0.21000000000000002,0.21000000000000002
qwen (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
qwen 1.5 (0.5b),,,,0.11,0.11
qwen 1.5 (72b),,,,0.94,0.94
qwen 2 1.5b instruct,,,,0.5199999999999999,0.5199999999999999
qwen 2 instruct (72b),,,,0.94,0.94
qwen 2.5 72b instruct turbo,,,,1.26,1.26
qwen 2.5 7b instruct turbo,,,,0.32,0.32
qwen chat (14b),,,,0.32,0.32
qwen chat (7b),,,,0.21000000000000002,0.21000000000000002
qwen-chat (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,,
qwen2 7b instruct,,,,0.94,0.94
redpajama-incite (3b),0.12999999999999998,0.12999999999999998,0.12999999999999998,0.11,0.11
redpajama-incite (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,,
redpajama-incite chat (3b),0.12999999999999998,0.12999999999999998,0.12999999999999998,0.11,0.11
redpajama-incite chat (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
redpajama-incite instruct (3b),0.12999999999999998,0.12999999999999998,0.12999999999999998,,
redpajama-incite instruct (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,,
remm-slerp-l2-13b,0.39,0.39,0.39,0.32,0.32
replit-code-v1 (3b),,0.12999999999999998,0.12999999999999998,0.11,0.11
snorkel mistral pairrm dpo (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,,
snowflake arctic instruct,,,,2.52,2.52
sqlcoder,0.12999999999999998,0.12999999999999998,0.12999999999999998,,
sqlcoder (15b),,0.39,0.39,0.32,0.32
stablelm base alpha 3b,0.12999999999999998,0.12999999999999998,0.12999999999999998,,
starcoder,0.39,0.39,0.39,,
starcoder (16b),,0.39,0.39,0.32,0.32
starcoderchat alpha (16b),,,,0.32,0.32
stripedhyena hessian (7b),0.25999999999999995,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
stripedhyena nous (7b),,0.25999999999999995,0.25999999999999995,0.21000000000000002,0.21000000000000002
toppy m (7b),,,,2.1,2.1
toppy-m-7b,0.25999999999999995,0.25999999999999995,0.25999999999999995,,
upstage solar instruct v1 (11b),0.39,0.39,0.39,0.32,0.32
vicuna fastchat t5 (3b),,,,0.11,0.11
vicuna v1.5 (13b),0.39,0.39,0.39,0.32,0.32
vicuna v1.5 (7b),,,,0.21000000000000002,0.21000000000000002
vicuna v1.5 16k (13b),,,,0.32,0.32
wizardcoder python v1.0 (34b),1.0399999999999998,,,0.8400000000000001,0.8400000000000001
wizardlm v1.2 (13b),0.39,0.39,0.39,0.21000000000000002,0.21000000000000002
zephyr 7b,0.25999999999999995,0.25999999999999995,0.25999999999999995,0.5199999999999999,0.5199999999999999
